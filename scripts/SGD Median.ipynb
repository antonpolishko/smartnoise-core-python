{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from scripts.pums_downloader import datasets\n",
    "\n",
    "from scripts.pums_sgd import PumsModule, load_pums, problem, evaluate, printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(load_pums(datasets[1]), batch_size=10000, shuffle=True)\n",
    "test_loader = DataLoader(load_pums(datasets[1]), batch_size=10000)\n",
    "# train_loader.sampler = RandomSampler(replacement=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc\t|\tloss\n",
      "0.93\t|\t135.83\n",
      "0.93\t|\t0.58\n",
      "0.93\t|\t5.82\n",
      "0.07\t|\t20.66\n"
     ]
    }
   ],
   "source": [
    "model_ = PumsModule(len(problem['predictors']), 2)\n",
    "gradients = dict((name, []) for name, _ in model_.named_parameters())\n",
    "\n",
    "printf(f\"acc\\t|\\tloss\")\n",
    "for batch in train_loader:\n",
    "    model = PumsModule(len(problem['predictors']), 2)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), .1)\n",
    "    loss = model.loss(batch)\n",
    "    loss.backward()\n",
    "    # gradients.append(list(model.linear1.parameters()))\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            grad = param.grad.detach().clone()\n",
    "            gradients[name].append(grad)\n",
    "    optimizer.step()\n",
    "    # print(model.linear1.weight.grad)\n",
    "    # print(model.linear1.bias.grad)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    accuracy, loss = evaluate(model, test_loader)\n",
    "    printf(f\"{accuracy.item():.2f}\\t|\\t{loss.item():.2f}\", force=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "# This should be a dp median\n",
    "import torch.nn as nn\n",
    "avg_linear1 = sum(gradients['linear1.weight'])  / len(gradients['linear1.weight'])\n",
    "avg_linear1_bias = sum(gradients['linear1.bias']) / len(gradients['linear1.bias'])\n",
    "avg_linear2 = sum(gradients['linear2.weight']) / len(gradients['linear2.weight'])\n",
    "avg_linear2_bias = sum(gradients['linear2.bias']) / len(gradients['linear2.bias'])\n",
    "\n",
    "model.linear1.weight = nn.Parameter(avg_linear1)\n",
    "model.linear1.bias = nn.Parameter(avg_linear1_bias)\n",
    "model.linear2.weight = nn.Parameter(avg_linear2)\n",
    "model.linear2.bias = nn.Parameter(avg_linear2_bias)\n",
    "\n",
    "acc, loss = evaluate(model, test_loader)\n",
    "acc, loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gradients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToDataframe(\n",
      "  data=Resize(\n",
      "    data=Cast(\n",
      "      data=[3.071223020553589, 1.9098789691925049, 1.085517168045044, 0.7798864841461182],\n",
      "      true_label=True,\n",
      "      lower=0,\n",
      "      upper=10,\n",
      "      atomic_type=float\n",
      "    ),\n",
      "    number_columns=1,\n",
      "    lower=0.0,\n",
      "    upper=10.0\n",
      "  ),\n",
      "  names=['linear1.weight']\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import opendp.smartnoise.core as sn\n",
    "\n",
    "with sn.Analysis():\n",
    "    grads = [x.mean().item() for x in gradients['linear1.weight']]\n",
    "    dataset = sn.literal(value=grads, value_public=False)\n",
    "    typed = sn.cast(dataset, atomic_type={\n",
    "        bool: 'bool', float: 'float', int: 'int', str: 'str'\n",
    "    }[float], true_label=True, lower=0, upper=10)\n",
    "    resized = sn.resize(typed, number_columns=1, lower=0., upper=10.)\n",
    "    data = sn.to_dataframe(resized, names=['linear1.weight'])\n",
    "    print(data)\n",
    "    candidates = [0., 3., 4., 7., 10., 12.]\n",
    "\n",
    "    median_scores = sn.median(\n",
    "         data,\n",
    "         candidates=candidates,\n",
    "         data_rows=len(gradients))\n",
    "    # print(median_scores.value)\n",
    "    # dp_median = sn.exponential_mechanism(median_scores, candidates=candidates, privacy_usage={\"epsilon\": 1.})\n",
    "    # print(dp_median.value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([949, 3])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    for x in batch:\n",
    "        print(x.size())\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "linear1.bias tensor([0., 0., 0., 0., 0.])\n",
      "linear2.weight tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "linear2.bias tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight\n",
      "tensor([[-0.1316, -0.0025,  0.1985],\n",
      "        [-1.0574, -2.3805, -0.5121],\n",
      "        [ 0.2873, -0.5425, -0.2715],\n",
      "        [-0.2792, -0.0577,  0.0040],\n",
      "        [-0.1770,  0.2283, -0.0225]])\n",
      "linear1.bias\n",
      "tensor([ 0.0158, -0.2395,  0.4055, -0.3556,  0.1591])\n",
      "linear2.weight\n",
      "tensor([[ 0.1364, -0.3030, -0.1385,  0.1452, -0.1271],\n",
      "        [-0.0288,  0.2484,  0.0787, -0.2871,  0.0441]])\n",
      "linear2.bias\n",
      "tensor([-0.3465,  0.6554])\n"
     ]
    }
   ],
   "source": [
    "for x,y in model.state_dict().items():\n",
    "    print(x)\n",
    "    print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'public': False, 'year': 2010, 'record_type': 'person', 'state': 'ct'}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}